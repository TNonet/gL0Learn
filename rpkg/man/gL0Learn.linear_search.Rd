% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/linear_search.R
\name{gL0Learn.linear_search}
\alias{gL0Learn.linear_search}
\title{Linear grid search minimization of gL0Learn regularized loss.}
\usage{
gL0Learn.linear_search(
  theta_opt,
  l0 = 0,
  l1 = 0,
  l2 = 0,
  lows = -1,
  highs = +1,
  atol = 1e-06,
  return_all = FALSE
)
}
\arguments{
\item{theta_opt}{Optimal theta value that we are minimizing approximation off}

\item{l0}{L0 regularization penalty. Must be a non-negative scalar}

\item{l1}{L1 regularization penalty. Must be a non-negative scalar}

\item{l2}{L2 regularization penalty. Must be a non-negative scalar}

\item{lows}{lower bound for x. Can be 0 but `highs` must not be 0 at the 
same time}

\item{highs}{upper bound for x. Can be 0 but `lows` must not be 0 at the same time}

\item{atol}{Step size between each successive point in linspace}

\item{return_all}{boolean flag wheter or not to return L(x, theta) for each 
value in linspace or just the arg min.}
}
\description{
Linearly searches a linspace from `lows` to `highs` to find arg 
min value of x for:
 L(theta_opt, x) = (|theta_opt - x|)**2 + l0|x|_0 + l1|x|_1 + + l2|x|_2
We ensure that 0 is included in search space.
}
